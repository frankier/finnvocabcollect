from os.path import join as pjoin


WIKIPARSE_DB = config["WIKIPARSE_DB"]
SVL12K_ENRICHED_PATH = config["SVL12K_ENRICHED_PATH"]
KAIKKI_FI = "kaikki.org-dictionary-Finnish.json"
KAIKKI_EN = "kaikki.org-dictionary-English-all-non-inflected-senses.json"


rule all:
    input:
        "wordlist.parquet",
        "wordlist.txt"


rule download_kaikki_fi:
    output:
        KAIKKI_FI
    shell:
        "wget -O {output} https://kaikki.org/dictionary/Finnish/kaikki.org-dictionary-Finnish.json"


rule download_kaikki_en:
    output:
        KAIKKI_EN
    shell:
        "wget -O {output} https://kaikki.org/dictionary/English/all-non-inflected-senses/kaikki.org-dictionary-English-all-non-inflected-senses.json"


rule download_numberbatch:
    output:
        "numberbatch-19.08.txt.gz"
    shell:
        "wget -O {output} https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-19.08.txt.gz"


rule select_language:
    input:
        "numberbatch-19.08.txt.gz"
    output:
        "numberbatch-{lang}.txt"
    shell:
        r"gzip -d < {input} | sed -n -e 's/^\/c\/{wildcards.lang}\///gp' > {output}"


rule convert_numberbatch:
    input:
        "numberbatch-fi.txt"
    output:
        "numberbatch_fi.vec",
    shell:
        "python -m finnwordlist.preproc.convert_numberbatch {input} {output}"


rule clean_convert:
    input:
        "lemma_freqs.csv"
    output:
        "lemma_freqs.parquet"
    shell:
        "python -m finnwordlist.preproc.clean_convert_df {input} {output}"


rule make_ordinal_blacklist:
    input:
        KAIKKI_FI
    output:
        "badcatlist.txt"
    shell:
        "python -m finnwordlist.ordinal_blacklist {input} {output}"


rule make_suffix_list:
    input:
        WIKIPARSE_DB 
    output:
        "suffixes.parquet"
    shell:
        "python -m finnwordlist.deriv.suffix {input} {output}"


rule make_compound_compositionality:
    input:
        defns = WIKIPARSE_DB,
        vectors = "numberbatch_fi.vec"
    output:
        "compound_compositionality.parquet"
    shell:
        "python -m finnwordlist.deriv.compound_compositionality {input.defns} {input.vectors} {output}"


rule make_loans:
    input:
        defns = WIKIPARSE_DB,
        en_kaikki = KAIKKI_EN,
        fi_kaikki = KAIKKI_FI
    output:
        "loans.parquet"
    shell:
        "python -m finnwordlist.loan {input.defns} {input.en_kaikki} {input.fi_kaikki} {output}"


rule make_full_wordlist:
    input:
        clean_df = "lemma_freqs.parquet",
        kotus = "kotus-sanalista_v1/kotus-sanalista_v1.xml"
    output:
        wordlist_full = "wordlist_full.parquet"
    shell:
        "python -m finnwordlist.make_full_wordlist "
        "{input.clean_df} {output.wordlist_full}"


rule make_wordlist:
    input:
        badcatlist = "badcatlist.txt",
        suffixes = "suffixes.parquet",
        compound_compositionality = "compound_compositionality.parquet",
        loans = "loans.parquet",
        wordlist_full = "wordlist_full.parquet",
        wordlist_derivtrim = "wordlist_derivtrim.parquet"
    output:
        wordlist = "wordlist.parquet"
    shell:
        "python -m finnwordlist.make_wordlist "
        "{input.wordlist_full} {input.wordlist_derivtrim} {output.wordlist}"


rule convert_wordlist_to_bare:
    input:
        "wordlist.parquet"
    output:
        "wordlist.txt"
    shell:
        "python -m finnwordlist.convert_wordlist_to_bare {input} {output}"


rule plot_en_wordlist_freqs:
    input:
        SVL12K_ENRICHED_PATH 
    output:
        "en_freq_hist.svg"
    shell:
        "python -m plot_en_wordlist_freqs {input} {output}"
